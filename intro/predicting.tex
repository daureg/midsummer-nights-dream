Let us summarize in one sentence the two previous sections. Learning in graphs provides many
insights, and many graphs are complex, in the sense of having edges expressing different semantics
and created for mixed reasons. The logical conclusion is that we want to learn in complex graphs.
However, this requires the edges of such graphs to be labeled with one of $k$ types of relationship.
In the examples presented above, this was already done. Yet we argue that efficiently labeling the
edges is an interesting problem, especially in the following three situations:

\begin{enumerate}

  \item There exists a function that can perfectly label any edge because it is tailored to this
    specific graph, but calling it is expensive. For instance, say we want to know whether two
    connected users of a social network are tied to each other through family, work, school or
    hobby. The labeling function in this case simply asks users to label their relationships,
    assuming the answers do not contain any noise. At the scale of Facebook, this would require
    asking hundred of questions to each user on average, which is quite time consuming. Furthermore,
    it would also cost marketing resource to convince users this is beneficial for them, and
    engineering time to ensure this information remain confidential. Likewise, in a biological
    network, determining whether two proteins interact positively or negatively with each other is
    achieved by a lab experiment, which requires time and material.

  \item All edges are already labeled, perfectly and without any cost, but the number $k$ of edge
    types is very large. Indeed, we have seen examples where they are hundreds or even thousands of
    edge types. Similarly to what happen in dimensionality
    reduction~\autocite{DimensionReduction10}, to make intuitive sense of such data, we want to
    reduce the number of edge types to less than ten. A natural way is to ask a domain expert to
    cluster edge types together. However, this is again time consuming, and does not necessarily
    make use of the topology of the graph.

  \item The input graph is actually unlabeled. That is, we observe interactions between the nodes,
    and we assume from domain knowledge that these interactions fall into $k$ categories. However,
    there is no reasonable way to come up with a specific labeling function. In
    \autoref{tab:edge_apps} \vpageref{tab:edge_apps}, we present several such examples, but for now
    we simply recall our earlier co-purchase network. As we mentioned, there are several reasons why
    two products could be bought together. Yet it is unlikely that customers will provide this type
    of feedback, for it does not bring them immediate advantage.
\end{enumerate}

In this thesis, we consider three versions of the problem of predicting edge types.
\begin{enumerate}

  \item The \esp{} problem, which takes as input the topology of a directed signed graph, and the
    label of some of the edges. The output is the label of the remaining edges. Therefore, it can be
    seen as a supervised binary classification problem.

  \item The same \esp{} problem, where the input graph is undirected. In this case, we consider an
    active variant where instead of being given a random training set of labels, we have a budget of
    queries we can use to request arbitrary labels.

  \item The \ecp{} problem, which takes as input an unlabeled, undirected multilayer graph, the
    attributes of all its nodes, and a number of edge types $k$. The output is a $k$ clustering of
    the edges, and a set of $k$ vectors describing the clusters in terms of node attributes.
    Therefore, it can be seen as an unsupervised clustering problem with side information.
\end{enumerate}

We now review existing approaches addressing these problems, in order to highlight our contribution
in the next section.

The modern formulation of the \esp{} on directed graphs can be attributed to
\textcite{Leskovec2010}. Their idea is to compute local features of the nodes based on the training
labels. Such features include variations on the node degree, such as the number of positive
outgoing edges or the number of negative incoming edges. These node features are combined into edge
features, and a supervised classification algorithm is trained. Several works have devised
additional features~\autocites{Bayesian15}{Yuan2017}, most notably based on scoring the nodes in a
Page Rank fashion~\autocites{traag2010exponential}{shahriari2014ranking}{wu2016troll}. These methods
are accurate, fast ---for they are local, and interpretable ---for the features are hand crafted.
The drawback is that this feature engineering is done mostly in an ad hoc way. On the other hand, it
is also possible to look at the problem from a global point of view, by completing the
signed adjacency matrix through low rank
factorization~\autocites{LowRankCompletion14}{OnlineCompletion17}. These methods are also accurate
and bypass feature engineering, but by nature, they require careful algorithms to scale with larger
networks. Finally, during the writing of this manuscript, several papers have been published, which
use embedding of the nodes in a low dimensional space, based on the training
labels~\autocites{SIGNet17}{SNE17}. This also avoids feature engineering but is global in nature and
not so interpretable.

One way to solve the problem on undirected graphs would be to apply the previous methods, having
first replaced every edge $(u,v)$ by two directed edges \euv{} and \evu{}. This is not quite
satisfactory, both from a theoretical but also practical point of view (see
\autoref{sub:need_for_a_directed_graph}). Instead, \textcite{Cesa-Bianchi2012b} draw a connection
between the \esp{} problem and the \pcc{} problem. Recall that given a fully labeled signed graph,
the solution to \pcc{} is a partition of the nodes that minimize the number of disagreement
edges~\autocite{Bansal2002}. \Textcite{Cesa-Bianchi2012b} assume that the signs are originally
consistent with an underlying, hidden $2$-clustering, but we only observe the signs after they have
been flipped \uar{}. In this case, they show that the optimal number of disagreements is a lower
bound of the number of mistakes of any active \esp{} algorithm. One natural approach would then be
to solve \pcc{} based on the observed signs, and predict the remaining signs consistently with the
inferred clusters. At first it seems hopeless, as \pcc{} is difficult to approximate on general
graphs~\autocite{Charikar2003}, even when there are only two clusters~\autocite{Giotis2006}.
However, this worst case analysis does not forbid more positive results on signed graphs that
exhibit stability under perturbation~\autocites{clusteringFeasibility15}{StableCC09}{StableLP09} or
are obtained through perturbations from an ideal case~\autocites{plantedAilon09}{Makarychev2014}.
Furthermore, in the active setting, the learner gets to choose which signs are observed. The general
idea of \textcite{Cesa-Bianchi2012b} is thus to use the query budget to build fully labeled paths
between each connected nodes. Those paths must be as short as possible, since the predicted sign of
$(u,v)$ is the product of the signs along the path from $u$ to $v$. Therefore, the shorter the path
and the less influence of the random perturbations. At the same times, those paths must span the
whole graph. This is the topic of an active research area~\autocites{Abraham2012}{Spanner17}.

As for the \ecp{} problem, to the best of our knowledge, it has not been studied under our
assumptions. A more common problem in attributed graphs is to cluster nodes into
communities~\autocites{LeskovecEgo12}{Yang2013}{Xu2014}{ZhangModelFree16}. However, it is not
immediate how such methods, generally based on generative models, could be adapted to our problem.
Direct approaches to classify edges have been proposed, based on graphical
models~\autocite{graphicalModelTies11}, nearest neighbors with a customized
distance~\autocite{Aggarwal2016a} and edge embedding in knowledge graphs~\autocite{transE13}. Yet
they all rely on having training labels as supervision. A simple unsupervised method is to cluster
the line graph of the input graph~\autocite{LineGraph09}, but this does not take advantage of
attributes. Another method uses topological features~\autocite{ahmed2017roles} but is rather complex
and thus not very interpretable. If we further assume that each edge type is associated with an
Euclidean space, and that the position of nodes in one space are not correlated with their position
in another space, then it is possible to recover an approximation of these Euclidean metrics in
polynomial time without any supervision~\autocite{Abraham2012a}.
