Graphs are useful to represent relationships between entities. In particular, a lot can be learned
from graphs encompassing several types of relations in one integrated structure. However, many
existing works assume that such graphs are given, before studying interesting properties like
community structure and information spreading. In this thesis instead, we develop methods to predict
the type of edges given a graph topology, a few initial label and possibly attributes of the nodes.
\smallskip

\paragraph{Learning on graphs}

Graph theory has been around for almost three centuries~\autocite{biggs1976graph}, and it provides a
conceptually simple yet immensely rich framework to model situations where entities are connected
with each other~\autocite{ComplexNetworksApp11}. Coupled with the increasing availability of large
amount of relational data, it has recently spurred a lot of interest across various and tangible
applications:
\begin{itemize}[nosep,leftmargin=*]
  \item community detection ~\autocite{FortunatoSurvey10} Describe the task in one sentence and give
    some nice examples from the survey, if possible supported by real-world numbers;
  \item semi-supervised learning ~\autocites{SSL06}{graphSSL14} Idem
  \item node classification ~\autocite{nodeClassif11} Idem
  \item node embedding ~\autocite{representationLearning17} Idem
  \item link prediction ~\autocite{linkPredSurvey16} Idem
  \item influence maximization ~\autocites{infmaxKempe15}{infmax13} Idem
  \item network evolution ~\autocite{networkEvolution14} Idem
\end{itemize}

\vspace{-\baselineskip}
\paragraph{Complex networks}

The prevalent setting for most of the works discussed above is that the graph connections are: (i)
homogeneous, in the sense that all edges are of a single type, having the same semantics  between
any pairs of nodes; and (ii) based on the \emph{homophily} principle~\autocite{Homophily01}, roughly
meaning that nodes are linked because they are similar. However, many real world situations require
a more complex model, with several kind of edges and where nodes can be connected if they are
similar only on some dimension or even if they are dissimilar. For instance, a e-commerce website
could allow its users to express whether they find the review of other users trustworthy or not. As
more involved example, consider a social network such as Facebook. Whereas the website offers only a
single \emph{friendship} relation, we may want to distinguish between family, colleague and sport
buddies~\autocite{egoNips12}. Moreover, among one user's \enquote{friend}, there might be some
relations that are actually not positive~\autocite{Yang2012}, whether because the receiving end if
spam or behave in strange way. Note finally that friendship is only kind of relationship between two
users of Facebook, we could also link them whenever they attend the same event or are tagged in the
same post. Yet another possibility would be to study the same set of users across multiple social
networks~\autocite{mergingNetworks16}, in which case the edge type could denote some common
combinations of connections (\eg Twitter+LinkedIn or Facebook+Instagram). In this thesis, we thus
defend the following statement: \textbf{There exists efficient and accurate methods to predict edge
type in complex networks (reyling either only on the graph topology or also on node metadata).}

A first motivation is that by labeling all edges, we can split a complex networks in a superposition
of simple networks with a single edge type, on which we can apply existing methods. Of course,
different kind of relation are intertwined, thus a second stronger motivation is to identify the
different layers in order to study their interactions.

\vspace{-\baselineskip}
\paragraph{Predicting polarity in directed social networks}

The first kind of such complex networks we consider are \emph{signed graphs}~\autocite{Tang2015a},
where edges carry a positive or a negative sign. Among the many applications of signed graphs, a
natural, and historical~\autocite{harary1953}, one is directed social networks. In such systems,
users can explicitly tag others, stating whether they trust them, support them, like them, or not.
Being able to predict edge signs in such networks improve the user experience, for instance by
promoting reasonable online debates~\autocite{journalism15}, assembling efficient teams within
companies~\autocite{MLinHR16} and mitigating cyberbullying~\autocite{cyberbullying13}. Existing
approaches attack the problem along several angles: finding a low dimensional representation of the
nodes based on their connection patterns~\autocites{SIGNet17}{SNE17}, finding low rank approximation
of the adjacency matrix~\autocites{LowRankCompletion14}{OnlineCompletion17} or extracting
topological features and training classifiers~\autocites{Leskovec2010}{Bayesian15}{wu2016troll}.
Guided by the idea that users exhibit various degree of trollness, we propose a simple sign
generative model. It naturally leads to two batch algorithms, one that probably approximate the
Bayes optimal predictor when the training set is dense enough and one that approximate the maximum
likelihood estimates through label propagation. Extensive experiments on synthetic and real datasets
show that in addition to their sound theoretical foundations, our methods are competitive with the
state of the art in predictive performance, while being more scalable. To illustrate this point, a
short extract of our results is showed in \autoref{tab:troll}.

\begin{table}[ptbh]
  \centering
  \caption{Matthews Correlation Coefficient measuring (the closer to 100 the better) in a \aut{}
    network as the proportion of labeled training edges grows. The best result is in red and the
  second one in blue.\label{tab:troll}}
  \vspace{0.5\baselineskip}
  \begin{tabular}{lccccc|r}
    \toprule
    {}               & 3\%                & 9\%                & 15\%               & 20\%               & 25\%               & time (ms)            \\
    \midrule
    \uslogregp{}     & \vsecondSig{15.19} & \vsecondSig{26.46} & 32.98              & 36.57              & 39.90              & 2                    \\
    \rowcolor{gray!20!white}
    \usrule{}        & 15.09              & 26.40              & \vsecondSig{32.98} & \vsecondSig{36.72} & 40.16              & \textbf{\textless 1} \\
    \rowcolor{gray!20!white}
    \uslpropGsec{}   & \vfirstSig{19.00}  & \vfirstSig{30.25}  & \vfirstSig{35.73}  & \vfirstSig{38.53}  & \vfirstSig{41.32}  & \textbf{16}          \\
    \midrule
    \compranknodes{} & 12.28              & 24.44              & 31.03              & 34.57              & 38.26              & 128         \\
    \complowrank{}   & 8.85               & 17.08              & 22.57              & 25.57              & 29.24              & 1894                 \\
    \compbayesian{}  & 10.91              & 23.75              & 32.25              & 36.52              & \vsecondSig{40.32} & 5398                 \\
    \comptriads{}    & 8.62               & 16.42              & 22.01              & 24.77              & 27.13              & \textbf{5}           \\
    \bottomrule
  \end{tabular}
\end{table}

\vspace{-\baselineskip}
\paragraph{Active learning in undirected signed graphs}

There are many other domains where signed graphs have proved useful. For instance in computer
vision, it is used to segment images in 2D~\autocites{Kim2011}{Bagon2011}{CellSeg14} or
3D~\autocites{VolumeSegmentation12}{Beier2015}, to simplify 3D shapes~\autocite{Shape3D17} and to
track target across sequential video frames~\autocite{multiTracking15}. When the nodes are words,
signed graphs are employed to identify coreference~\autocites{graphicalCoreference04}{Elsner2009} or
cluster synonym words~\autocite{SignedWordRatings}. They plays a large role in biology, to clusters
genes~\autocite{Ben-Dor99}, identify mutation regions in chromosomes~\autocite{Das2015} or finding
stable subsystems~\autocite{monotoneBiology07}. Finally, given large databases with duplicated
records, they naturally help solving entity
resolution~\autocites{Crosslingual07}{DeDup09}{LargeScaleDeDup09}{WeightedER14}.

In all these cases, graphs are not directed and nodes are not human beings, meaning we can hardly
assign them trollness.  Therefore, we make a different assumption, positing that nodes are
partitioned in $K$ groups in such a way that links within groups are positive and links across
groups are negative. Recovering the optimal partition after observing all the signs of a graph is
called \pcc{}~\autocite{Bansal2002} in the Machine Learning field. Whereas it has been proved to be
\NPc{} to even approximate in the worst case~\autocites{Charikar2003}{Demaine2006}, our thorough
literature review paints a less gloomy landscape. Not only does there exist
exact~\autocite{Berg2015} and fixed parameters algorithms~\autocites{GoldenCE12}{Fomin2014},
efficient approximation~\autocites{CCPivotConf05}{ChawlaArxiv14} and large scale
heuristics~\autocites{Levorato2015}{Facchetti2011isingmodel}{Kappes2016}, but beyond the worst case,
we are interested in instances that exhibit stability under
perturbation~\autocites{clusteringFeasibility15}{StableCC09}{StableLP09} or are obtained through
random moves from an ideal case~\autocites{plantedAilon09}{Makarychev2014}. This leads us to develop
a spanning tree tailored to predicting edge signs in such a setting, which we call \gtx{}. It does
so by aiming to approximately preserve the distances in the
graph~\autocites{LowerBound95}{Abraham2012}. We present preliminary results showing that on certain
kind of graphs, this indeed results in better predictive performance than a competitive baseline.
Namely, we create synthetic graphs of growing size with the \lpa{} model~\autocite{Barabasi1999},
partition the nodes in two clusters, set the edge signs accordingly and finally flip a fraction of
them \uar{}. As showed on \autoref{fig:gtx_xp_pasynthmcc}, \gtx{} always predict signs better than a
\bfs{} tree rooted at the highest degree node, especially when the noise level is low, and is less
sensible to the graph size.

\begin{figure}[phtb]
  \centering
  \includegraphics[width=.6\textwidth]{gtx_exp/pasynthmcc}
  \caption{Synthetic \lpa{} }\label{fig:gtx_xp_pasynthmcc}
\end{figure}

\vspace{-\baselineskip}
\paragraph{Predicting more than two kinds of relations}

Finally, we consider the case where there are more than two possible type of relations, which is
often called \emph{multilayer graphs}~\autocites{Kivela2014}{multiSurvey14}. In addition, we assume
that the graph is attributed, that is every node is described by a vector of numeric features called
the \emph{profile} of the node. Our assumption is then that links cannot be fully described by a
global homophily. Thus we take a more nuanced view, combining partial homophily (that is, nodes are
connected when they are similar on a subset of the attributes) and heterophily (that is, nodes are
connected when they are dissimilar on a subset of the attributes). As examples of the latter, think
of dating websites ---where most users are linked with users of the opposite
gender~\autocites{homophilyMyspace09}{Tinder16}; spreading innovation ---where meeting people with
different background and point of view is crucial to favor diversity and
creativity~\autocite{rogers2003diffusion}; and online news consumption ---where connecting people
from different sides of the political spectrum helps avoiding echo chambers and fueling a democratic
debate~\autocite{balancedNews17}. More generally, multilayer graphs have applications in various
fields. In social networks, where players of the Pardus massively multilayer online game can have
six types of relations (friendship, enmity, private message, trading, aggression and
bounty)~\autocite{Szell2010} or where photo sharers of the Flickr website can interact in eleven
ways (either directly or through comments, tags, groups and so on)~\autocite{RecoFlickrMulti11}. In
citation networks, where authors of the DBLP dataset are connected if they have co-authored a paper
in one the \np{1000} conferences that form the edge type~\autocite{communityDBLPbyConf05}, or where
\np{5000} SIAM papers can be connected for five reasons (abstract similarity, title similarity,
keywords similarity, author similarity or citation)~\autocite{articlesMultiSim11} in economic
networks, where 951 ports are connected by 3 kind of ships (bulk dry carriers, container ships and
oil tankers)~\autocite{ports3kindofships10} or in the International Trade Network, where 162
countries are connected by 96 kind of commodities they can exchange~\autocite{worldTradeNetwork10}.
And in biology, where genes co-expression network under 130 different experimental
conditions~\autocite{bioLayerExp11}

Existing works ~\autocite{egoNips12}

The social circles model defines a generative for connection inside ego
networks~\autocites{LeskovecEgo12}{LeskovecEgo14}. Basically, each node makes friends along $K$
categories and we learn the parameters that maximize the probability for each edge to belong to one
of the $K$ categories\footnote{But those categories can change from node to node.}.

Yixiang Fang, Reynold Cheng, Siqiang Luo, and Jiafeng Hu. 2016. Effective community search for large
attributed graphs. Proc. VLDB Endow. 9, 12 (August 2016), 1233-1244. DOI:
\url{http://dx.doi.org/10.14778/2994509.2994538}

Look for attributed community,  which are subgraphs satisfying both structure cohesiveness (i.e.,
its vertices are tightly connected) and keyword cohesiveness (i.e., its vertices share common
keywords),  enabling a better understanding of how and why a community is formed
To enable efficient AC search, we develop the CL-tree index structure and three algorithms based on
it. We evaluate our solutions on four large graphs, namely Flickr, DBLP, Tencent, and DBpedia. Our
results show that ACs are more effective and efficient than existing community retrieval approaches.



Find partitions by maximizing the densite of intra community edges, but weight the edge between $i$
and $j$ by a function that depends both of the $i$ and $j$ profile similarities and a learned weight
vector per community~\autocite{ZhangModelFree16}. Solved by alternating optimizing over node
assignment and over community weight learning.
vector 

each node can be seen as a point in $R^d$ and because the dimensions are assumed to be not
independent, each point belong to a subspace. It's a well studied problem~\autocite{SCSurvey11}

Recovering $d$ different metric spaces whose intersection form the observed social multiplex in
almost linear time with bounded distortion~\autocite{Abraham2012a}. Assume there are $K$ social
categories modelled by Euclidean spaces $\mathcal{D}_i$. Users in there are near uniformly
distributed and categories have small local correlation:
\[ \forall i\neq i', \; \forall r, r' = O(polylog(n)),\,
  \forall u, u',\, |\mathcal{B}_i(u, r) \cap \mathcal{B}_{i'}(u', r')| \leq O(\log n) \]
These spaces give rise to small world networks $\mathcal{G}_i$ with edge probability $\propto
\mathcal{D}_i(u, v)^{-d}$ and we observe the real network $\mathcal{G} =\bigcup_i \mathcal{G}_i$.
From $\mathcal{G}$, the proposed algorithm recovers in $n \mathrm{polylog} n$ time a bounded
approximation $\mathcal{D}'_i$ of all $\mathcal{D}_i$
\[ \sigma \mathcal{D}_i(u, v) \leq \mathcal{D}'_i(u, v) \leq \delta \mathcal{D}_i(u, v) + \Delta \]

As hinted by the title, \autocite{Ahmed2016}\footnote{published version in
\autocite{ahmed2017roles}?} is a specific instantiation of a more general framework
about Role Discovery in Networks by the same authors. Originally, two nodes were said to have the
same role if they were structurally equivalent (that is, connected to the rest of the network in
identical ways). Hereafter, structural equivalence is relaxed into mere similarity. Furthermore, the
entities under consideration are now edges instead of nodes.
The framework has two main steps:
1) Automatically extracting a feature matrix X from an attributed graph
2) Applying clustering or factorization methods on X to assign roles to edges

The first step is mostly based on counting the number of k-motifs in which edges is involved,
although the authors stresses that their method could easily be extended to handle features derived
from node attributes. Letting m be the number of edges, the output of this step is a $m\times f$
matrix X of edge features.

In the second step, the authors seek a low rank approximation of X. Namely, they
want to minimize the Bregman divergence between X and UVT, where U and V are
two non-negative matrix of rank at most r. The optimization is carried out by a
parallel coordinate descent method called PCMF-BASIC and described in a separate
journal article: Parallel collective factorization for modeling large heterogeneous
networks.
There is also a regularization term, which is not given explicitly (although it
might have something to do with ensuring UVT sparsity). The rank r is chosen
dynamically through a Minimum Description Length approach.

The article ends with an extension to time evolving graph and some experimental
illustrations on the Enron mail dataset (and a citation one I assume). They also
give an example of application: detecting malicious user in Social Network. While its
node and most of its edges are normal, some edges might not be (harassment,
scam, …)

Stattner, Erick, and Martine Collard. "Link Clustering for Extracting Collaborative Patterns in a Scientific Co-Authored Network.", FAB workshop, ANOSAM 2017
they use their method of conceptual links
Groups of nodes are first created when they have common attributes. The set of links between two
groups is called a conceptual link in the sense that it corresponds to a relationship between two
sets of attributes, namely two concepts in the field of formal concept analysis [7]. The number of
links between two groups is then evaluated and when the frequency is greater than a given support
threshold $\beta$, we talk about frequent conceptual link. Note that we only keep maximal frequent conceptual links (mfcl), i.e. those who are not included in others.
Finally, the set of maximal frequent conceptual links is used to create a new network structure called a conceptual view which summarizes all the knowledge extracted from the initial network. In a conceptual view, each node corresponds to a set of attributes (in this context we call them Meta-nodes) and a link corresponds to maximal frequent conceptual links.
A formal presentation of frequent conceptual links can be found in [18].

Our approach is to seek a small number of vectors that, once assigned to every edge, best explain
the graph (\ie maximize a score function between the edge vector and the profiles of its endpoints).
From this initial formulation, we derive two optimization problems, and initially solve them on
synthetic data, generated with a few natural topological constraints. We compared these solutions
with the result of a baseline approach that simply clusters the pairwise profile vectors using
$k$-means.

% Surveys are also available about applications of unsigned networks
% such as data classification [Sen et al. 2008], recommendation [Tang et al. 2013], and
% information propagation [Chen et al. 2013a]

While our thesis is therefore primarily concerned with learning on graphs, instead of focusing at
nodes (to predict their class, their cluster or to find their representation), we look at edges (\ie
pairs of nodes), and instead of having one kind of relationship, we have two, or more than two when
the nodes are attributed.
