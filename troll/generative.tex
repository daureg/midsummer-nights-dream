\section{Generative Model for Edge Labels}\label{s:gen}

We now define the stochastic generative model for edge labels we use in the batch learning setting.
Given the graph $G = (V,E)$, let the label $\yuv \in \spin$ of directed edge $(u,v) \in E$ be
generated as follows. Each node $u \in V$ is endowed with two latent parameters $p_u, q_u \in
[0,1]$, which we assume to be generated, for each node $u$, by an independent draw from a fixed but
unknown joint prior distribution $\mu(p,q)$ over $[0,1]^2$. Each label $\yuv \in \spin$ is then
generated by an independent draw from the mixture of $p_u$ and $q_v$
$$\Pr\big( \yuv = 1 \big) = \tfrac{p_u + q_v}{2}$$
This process is illustrated in \autoref{fig:troll_genmodel}.
\begin{marginfigure}
	\centering
	\includegraphics[width=0.98\linewidth]{tikz/troll_genmodel_tikz}
	\caption{The sign \yuv{} of the edge \euv{} is positive with probability $\frac{1}{2}(p_u+q_v)$.
	\label{fig:troll_genmodel}}
\end{marginfigure}

The basic intuition is that the nature $\yuv$ of a relationship \euv{} is stochastically
determined by a mixture between how much node $u$ tends to like other people ($p_u$) and how much
node $v$ tends to be liked by other people ($q_v$). In a certain sense, $1-tr(u)$ is the empirical
counterpart to $p_u$, and $1-un(v)$ is the empirical counterpart to $q_v$. One might view
our model as reminiscent of standard models for link generation in social network analysis, like the
classical $p_1$ model from \cite{hl81}. However, note that the similarity falls short, for all these
models aim at
representing the likelihood of the network topology, rather than the probability of edge signs, once
the topology is \emph{given}.

Notice that the Bayes optimal prediction for $\yuv$ is $y^*(u,v) = \sgn\big(\eta(u,v) -
\tfrac{1}{2}\big)$, where $\eta(u,v) = \Pr\big( \yuv = 1 \big)$. Moreover, once all the signs have
been generated, we can compute the expected number of positive edges outgoing from $u$ as the
expected value of the random variable $P_u = \sum_{v\in \NNout(u)} \Ind{\yuv = +1}$. Using this, we
have that the probability of
drawing at random a $+1$-labeled edge from $\Nout(u)$ equals
\begin{equation}\label{e:pout}
	\frac{\E\left(P_u\right)}{\dout(u)} =
	\frac{1}{\dout(u)} \sum_{v\in \NNout(u)} \frac{p_u + q_v}{2} =
	\frac{1}{2}\,\Biggl(p_u + \frac{1}{\dout(u)} \sum_{v\in \NNout(u)} q_v \Biggl) =
		\frac{1}{2}\,\left(p_u + \qbar_u\right)\,,
\end{equation}
where $\qbar_u = \frac{1}{\dout(u)} \left( \sum_{v\in \NNout(u)} q_v \right)$ is the average $q$
value of $u$ out neighbors.
Similarly, the probability of drawing at random a $+1$-labeled edge from $\Nin(v)$ equals
\begin{equation}\label{e:pin}
	\frac{1}{2}\,\Biggl(q_v + \frac{1}{\din(v)} \sum_{u\in \NNin(v)} p_u \Biggl)=
		\frac{1}{2}\,\left(q_v + \pbar_v\right)
\end{equation}
