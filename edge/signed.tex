\paragraph{Connection with signed graphs}
\label{par:generalization_of_signed_graphs}

The learning bias of \autoref{sub:bias_balance} implicitly defined an idealized \esp{} problem as:
\begin{problem}[idealized \esp{}]
  \label{p:edge_esp}
  Given $n$ nodes belonging latently to $K$ groups, predict whether two nodes $u$ and $v$ belong to
  the same group (that is $(u,v)$ is positive) or not (that is $(u,v)$ is negative).
\end{problem}
In \autoref{sec:gtx} we study in particular the important special case where $K=2$. Now consider an
instance of \autoref{p:edge_full} where $k=2$, and where the profiles and edges are based on group
membership. We now check that the optimal solution of such an instance is consistent with the
solution of this idealized \esp{} problem on the same graph.

Let us first define this instance formally. Given a graph $G=(V,E)$, call the $K=2$ groups of
\autoref{p:edge_esp} $L$ and $R$. We then define the nodes profiles $X$ as follow. We first draw \uar{} a vector $p$
from $\{-1, 1\}^d$, then let the profiles in $L$ be $\frac{p}{\sqrt{d}}$ and the
profiles in $R$ be $-\frac{p}{\sqrt{d}}$. We call this instance $\mathcal{I} = (G, X, k=2)$. With
this choice, we have
\begin{equation*}
  s_{uv} =
  \begin{cases}
    \frac{\onev}{d} = s_{\mathrm{inner}} & \quad \text{if $u$ and $v$ are in the same group,} \\
    -\frac{\onev}{d} = s_{\mathrm{outer}} & \quad \text{if $u$ and $v$ are in different groups.}
  \end{cases}
\end{equation*}
Let us denote by $m_i$ the number of edges that are internal to $L$ and $R$, and by $m_o = |E| -
m_i$ the number of edges between $L$ and $R$.

\begin{prop}
  Let $\mathcal{D}_2 = \{w_1^\star, w_2^\star\}$ be an optimal solution of \autoref{p:edge_full} on the
  instance $\mathcal{I}$. Then $\mathcal{D}_2$ provides the following solution to
  \autoref{p:edge_esp}: each every edge explained by $w_1^\star$ is predicted positive, and every
  edge explained by $w_2^\star$ is predicted negative.
\end{prop}
\begin{proof}
  Take any $w_1, w_2 \in \dsphere \times \dsphere$ such that $w_1 \neq w_2$. Assume without loss of
  generality that $w_1 = \argmax_{w\in \{w_1, w_2\}} {s_{\mathrm{inner}}}^T w$. This implies that:
  \begin{equation*}
    {s_{\mathrm{inner}}}^T w_1 = \frac{1}{d}\sum_{i=1}^d {w_1}_{;i} >
    \frac{1}{d}\sum_{i=1}^d {w_2}_{;i} = {s_{\mathrm{inner}}}^T w_2 \,.
  \end{equation*}
  In turn, we have that:
  \begin{equation*}
    {s_{\mathrm{outer}}}^T w_2 = -\frac{1}{d}\sum_{i=1}^d {w_2}_{;i} >
    -\frac{1}{d}\sum_{i=1}^d {w_1}_{;i} = {s_{\mathrm{outer}}}^T w_1 \,.
  \end{equation*}
  We can thus rewrite the maximization objective \eqref{eq:edge_full} of \autoref{p:edge_full} as:
  \begin{align}
    \label{eq:edge_special}
    \argmax_{w_1,w_2 \in \dsphere} & \quad \sum_{u,v \in E} \max_{w \in \{w_1, w_2\}} {s_{uv}}^T w = \\
    \argmax_{w_1,w_2 \in \dsphere} & \quad
    \sum_{\substack{u,v \in E\\ s_{uv} = s_{\mathrm{inner}}}} {s_{\mathrm{inner}}}^T w_1 +
    \sum_{\substack{u,v \in E\\ s_{uv} = s_{\mathrm{outer}}}} {s_{\mathrm{outer}}}^T w_2 = \notag \\
    \argmax_{w_1,w_2 \in \dsphere} & \quad m_i {\frac{\onev}{d}}^T w_1  + m_o {\frac{-\onev}{d}} ^T w_2 \notag
  \end{align}
  One can check using Lagrange multipliers that for any $c \in \Rbb^n$, $\max_{w \in \dsphere} c^T w
  = \frac{c}{\|c\|}$. The solution of \eqref{eq:edge_special} is therefore:
  \begin{equation*}
    w_1^\star = \frac{\onev}{\sqrt{d}} \qquad \text{and} \qquad w_2^\star = \frac{-\onev}{\sqrt{d}}
  \end{equation*}
  As claimed, the edges associated with $w_1^\star$ (respectively $w_2^\star$) are the edges that
  are to be predicted positive (respectively negative) in \autoref{p:edge_esp}.
\end{proof}

This is nothing more than a sanity check, as the profiles explicitly encode the membership of each
node to one of the two groups. Indeed, the proof makes no use of the dimension $d$ of the profiles,
so that $d=1$ would be enough. Slightly more interesting is the case were those profiles are set up
as before, but perturbed \uar{}. Namely, the sign of each coordinate is changed with probability $p
< \shalf$. One can then check that
\begin{equation*}
  \E \left[ s_{\mathrm{inner}} \right] = \frac{(1-2p)^2}{d} \onev =
  -\E \left[ s_{\mathrm{inner}} \right] 
\end{equation*}
and that furthermore, the variance of each component is $\frac{8(p-p^2) - 16(p-p^2)^2}{d^2}$. While
the previous $\{w_1^\star, w_2^\star\}$ solution is now only optimal in expectation, we see that the
variance decrease quadratically with the dimension of the profiles. In practice we thus expect this
solution to be very close to the optimal. Intuitively this can be seen as taking the majority of $d$
votes on whether each node belongs to one group or the other.

\begin{aside}
  It is natural to ask how this result can be extended to more than $K=2$ groups. The most natural
  idea is to use one-hot encoding of the group membership as profiles, with additional negative
  values as in the example of \autoref{fig:edge_exe}. Namely, set the profiles of the \ith{} group
  as follow: all component are equal to $-b$ except for the \ith{} one, which is equal to $a$, where
  $a$ and $b$ are real constants such that $a^2 + (K-1)b^2=1$. However, in that case, we check
  numerically that $w_+ = \frac{\onev}{\sqrt{d}}$ and $w_- = \frac{-\onev}{\sqrt{d}}$ is the not the
  optimal solution, and that a solution achieving a larger objective function value does not cluster
  the edges between inner and outer groups.
\end{aside}
