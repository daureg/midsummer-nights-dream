As mentioned earlier, most real signed graphs are not fully balanced and thus do not have a
perfectly consistent clustering. The problem of quantifying how much a given graph departs from this
ideal situation is called \pcc{}. After defining it formally in \autoref{sub:problem_setting}, we
show that \pcc{} is a learning problem on its own, and discuss how it relates to the binary
classification problem of predicting edge signs, among many others applications. We then present
numerous methods to solve \pcc{} in \autoref{sub:state_of_the_art}, ranging from exact methods (that
implicitly leverage our bias) to heuristics (whose greedy and energy minimization frameworks are
classic in unsupervised graph cut problems). We also devote a large section to approximation
methods, in order to get a sense of why the problem is \NPc{} and even hard to approximate. This
allows us to finish in
\autoref{sub:cc_non_worst_case} by describing situations related to our bias where is possible to
solve the problem efficiently and optimally. In this section, we thus update existing surveys on the same
topic~\autocites{bonchi2014correlation}{surveyCC16}{CCWirth2017} and highlight the importance of
\pcc{} to solve our binary learning problem.

% surveyCC16 is about mind on complete graph (ie cluster editing). They give a Russian article from
% 1971 that says it cluster editing on triangle-free graph can be solved in polynomial time, which
% include bipartite graph (so for CC, if G^+ is (complete? I think so) bipartite)
% Fridman, G.Š.: A graph approximation problem. Upravlyaemye Sistemy 8, 73–75 (1971). (in Russian)
% In [14] it was observed that the problem is polynomially solvable for instances of at most 2
% clusters??! Actually it means consensus clustering can be solved in polynomial time when there are
% only 2 clustering as input

\subsection{Problem setting and connection to \esp{}}
\label{sub:problem_setting}
\input{cc_problem_and_esp}

\subsection{State of the art}
\label{sub:state_of_the_art}

\input{cc_state_of_art}

\subsection{Beyond worst case instances}
\label{sub:cc_non_worst_case}

\input{cc_non_worst_case}

\begin{aside}
\subsection{Variants and extensions}
\label{sub:variants_and_extensions}
\input{cc_variants}
\end{aside}

Let us review this material about \pcc{} in the light of our thesis objective: efficiently and
accurately characterize edges in complex networks, or rather signed graphs in this chapter. The
results on the hardness of \pcc{}, and the fact that the best approximations rely on a linear
program with a large number of constraints seems to run counter to such efficiency and accuracy
requirements. To avoid this pitfall, we presented many existing heuristics. More importantly, recall
that our learning bias is that nodes are assigned to $K$ groups, and that signs are consistent
with those groups. Informally, the closer an input signed graph is to this ideal situation, the more
regular it is with respect to this bias, and thus the easier the \esp{} problem is. Accordingly, the
works described in \autoref{sub:cc_non_worst_case} point out that such non worst case instances are
indeed where we expect clustering algorithms to be able to identify those $K$ groups with little to
no error. In the next section, we present an algorithm relying on a similar intuition, in an active
setting and where $K=2$.
