\subsection{Summary}

In this chapter, we expanded our efforts on characterizing edges in complex networks by addressing
the \esp{} problem in undirected signed graphs. We first demonstrated, conceptually and practically,
that the methods we designed in \autoref{chap:troll} are not suitable to this new setting. Drawing
on the well established theory of social balance, we therefore came up with a different learning
bias. More precisely, we posit that nodes latently belong to $K$ groups. Then that the edge signs
are initially set to be positive if both endpoints belong to the same group and negative otherwise.
And that finally we observe such assignment after it had been perturbed \uar{}.

We connected twice this bias for the \esp{} problem with the \pcc{} problem. First, solving \pcc{}
on a training set would provide us with the most reasonable partition of the nodes into $K$ groups,
allowing us to predict the test signs accordingly. Second, the optimal value of the \pcc{} objective
is a measure of the difficulty of the \esp{} problem~\autocite{Cesa-Bianchi2012b}. We thus presented
a detailed overview of the \pcc{} problem and its proposed solution. Our goal was to point out that
despite its hardness in the worst case, there exist efficient heuristics in practice, as well as
methods with formal guarantees in more favorable cases. We furthermore noted that such cases are
those when the sign assignment is close to follow our bias.

Such general \pcc{} approaches would typically be used in a batch setting. In the last part of this
chapter, we instead shifted our attention to the active setting, in the special case where $K=2$.
This allowed us to exploit our bias in a more specific way. Namely, we described an implementation
of the \gtx{} spanning data structure~\autocite{gtxFabio}. The idea is to query the sign of edges
that connect the endpoints of every other edge by the shortest possible path.  Our experiments
showed that this \gtx{} construction used in active \esp{} is competitive for some classes of
graphs.

\subsection{Future work}

Beyond those preliminary experiments, we could push further our methods along several directions:

\begin{enumerate}[1)]

	\item The basic analysis \autoref{prop:gtx_correct} shows that on any graph with $n$ nodes, the
		\gtx{} will perform at most $n$ collapses before terminating. However, as we mentioned
		\vpageref{par:number_of_iteration} at the end of \autoref{sub:gtx_algo}, we believe that this
		maximum number of collapses might be as low as $O(\log n)$. It turns out we were not able to
		prove this statement. This is unfortunate, for besides giving us guarantees on the algorithm
		runtime, this would also inform us about the stretch of the resulting tree. Indeed, let us
		consider the reverse direction in which the \gtx{} algorithm operates. That is, instead of a
		sequence of collapses transforming the original graph into a single node, we look at a sequence
		of expansions turning this single node into the original graph. Informally, the length of the
		longest path can only increase by a factor of five as each pair of nodes in $G_{t+1}$ expands
		into two connected stars in $G_{t}$.\footnote{More precisely, consider the edge $(u,v)$ in
		$G_{t+1}$. The two nodes are expanded into the two stars $s_u$ and $s_v$ in $G_t$, respectively
		with peripheral nodes $\{u_1, \ldots, u_k\}$ and $\{v_1, \ldots, v_\ell\}$ and center $c_u$ and
		$c_v$. In the worst case, there is now a path of length $5$ in $G_t$, \eg{} $(u_1, c_u, u_k,
		v_\ell, c_v, c_1)$.} Whereas the behavior of the average stretch is less straightforward, it is
		reasonable to expect that the smaller the number of expansions, the lower the stretch.

	\item As mentioned in \autoref{sec:troll_related}, \esp{} could be extended to weighted signed
		graphs. This is also relevant in undirected signed graphs. For instance, the signs might have
		been generated by thresholding an expensive symmetric similarity function. In that case, we
		might want to avoid extra evaluation of that function by predicting the signed weight of some
		new edges. A natural way to modify the \gtx{} algorithm is the following. When choosing the
		center of stars, pick the node with the current highest weighted degree. When choosing an edge
		to connect two center, pick among the edges with the lowest endpoints eccentricity the one with
		the lowest weight. What is less clear is to which extent such changes would affect the analysis.

	\item We wish we had more time to further explore \pcc{} under stability assumptions, especially
		as a way to handle the case where $K>2$. Recall that a clustering instance, made of a weighted
		graph and a partition objective, is \emph{$\alpha$-stable} (with $\alpha>1$) if its optimal
		partition remains the same whenever every weight $w_i$ is multiplied by a factor $c_i$ between
		$1$ and $\alpha$. Furthermore, we say that an algorithm is \emph{robust} if, given a clustering
		instance $\mathcal{I}$, it yields of the two following outcomes in polynomial time:
		\begin{enumerate}[(i),nosep]
			\item if $\mathcal{I}$ is $\alpha$-stable, returns the optimal solution of $\mathcal{I}$;
			\item if $\mathcal{I}$ is not $\alpha$-stable, either returns the optimal solution of
				$\mathcal{I}$ or reports that $\mathcal{I}$ is not $\alpha$-stable.
		\end{enumerate}
		This is a handy property because, in general, we cannot practically check the stability of an
		instance. Indeed, since we do not know the optimal solution, we cannot tell whether it changes
		or not under perturbations.

		As an example, let us consider the \minmc{} problem. Given a weighted undirected graph $G$ and a
		set of $k$ terminal nodes, the goal is to partition $G$ into $k$ clusters, each containing
		exactly one terminal, such that the total weight of edges across clusters is minimized. This
		bears some superficial similarity with \mmc{}. Recall from \autoref{ssub:cc_harness_approx} that
		\mmc{} requires us the find the lightest set of edges to cut in order to separate $k$ pairs of
		nodes.  Recall further that \mmc{} is equivalent to \pcc{}. As for \minmc{}, we can cast it as a
		\pcc{} problem~\autocite[Theorem 24]{Bansal2004}. Interestingly, there exists a robust
		algorithm for $2-\nicefrac{2}{k}$-stable instances of \minmc{}~\autocite{StableCC17}.  Under the
		assumption that graphs obeying our learning bias are $\alpha$-stable, for some $\alpha$
		depending of the graph irregularity, having such a stable algorithm for \mmc{} would be very
		valuable.  However, this might prove challenging. Indeed, \mmc{} is harder than \minmc{}, as
		illustrated by their respective approximation factor, $O(\log n)$ and less than
		$1.3$~\autocite{minmcApprox17}.

\end{enumerate}
