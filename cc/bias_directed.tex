Having two parameters per node, one for outgoing edges and another one for incoming edges, clearly
targets directed graphs. Many online interactions are inherently directed, for instance friendship,
trust or communication. On the other hand, predicting edge signs in undirected graphs is an equally
relevant objective. A prime example of such a situation is when we are given $n$ objects, some
pairwise similarities them, and the similarity function itself, which unfortunately takes an
exorbitant time to be evaluated. There is an underlying graph and being able to predict the sign of
its undirected edges would save us expensive evaluations of the symmetric similarity function.

A trivial way to turn an undirected graph $G$ into a directed graph $G'$ is to let $V'=V$ and, for
every edge $(u,v)$ in $E$, to add both \euv{} and \evu{} to $E'$ with the same sign as $(u,v)$. In
terms of our generative model, this corresponds to putting all the probability mass of $\mu$ on the
$p=q$ diagonal. This is clearly not a very satisfactory solution, for it removes one degree of
freedom from the model. To illustrate this point, we conduct the following experiment. We use our
previous \dssn{} datasets and remove the edge direction. As mentioned earlier, for a few pair of
nodes, there are reciprocal edges of different signs, in which case we pick a sign arbitrarily. Given
those undirected graphs, we orient them using the approach described above and compare our method
with the \complowrank{} approach ran directly on the undirected graphs. This is a fair comparison,
for \complowrank{} is designed to works solely on undirected graphs.

As we can see in \autoref{tab:bias_exp_undir}, our methods perform worse than when running on the
original directed graphs. Looking at \uslpropGsec{} on a 15\% training set as an example, we observe
that the MCC decreases by one (\kiw{}) to almost ten (\epi{}) points. On the other hand, the
\complowrank{} seems to perform better. Recall however that because it is an undirected method in
the first place and because we roughly double the number of signed edges, a 15\% training size means
the algorithm gets to observe more signs and therefore perform better. This small experiment thereby
shows that although the performance remains decent, not having direction information hurts our bias.

\input{bias_exp_undir}
